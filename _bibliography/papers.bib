---
---

@string{aps = {ieee,}}



@inproceedings{10.1145/3511808.3557130,
author = {He, Pengfei and Liu, Haochen and Zhao, Xiangyu and Liu, Hui and Tang, Jiliang},
title = {PROPN: Personalized Probabilistic Strategic Parameter Optimization in Recommendations},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557130},
doi = {10.1145/3511808.3557130},
booktitle = {Proceedings of the 31st ACM International Conference on Information & Knowledge Management},
pages = {3152–3161},
numpages = {10},
keywords = {recommender system, demographic information, reinforcement learning, strategic parameter optimizing},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@article{JMLR:v24:21-1254,
  author  = {Nicolas Garcia Trillos and Pengfei He and Chenghui Li},
  title   = {Large sample spectral analysis of graph-based multi-manifold clustering},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {143},
  pages   = {1--71},
  url     = {http://jmlr.org/papers/v24/21-1254.html},
  abstract = {In this work we study statistical properties of graph-based algorithms for multi-manifold
clustering (MMC). In MMC the goal is to retrieve the multi-manifold structure underlying a
given Euclidean data set when this one is assumed to be obtained by sampling a distribution
on a union of manifolds M = M1 ∪ · · · ∪ MN that may intersect with each other and
that may have different dimensions. We investigate sufficient conditions that similarity
graphs on data sets must satisfy in order for their corresponding graph Laplacians to
capture the right geometric information to solve the MMC problem. Precisely, we provide
high probability error bounds for the spectral approximation of a tensorized Laplacian on
M with a suitable graph Laplacian built from the observations; the recovered tensorized
Laplacian contains all geometric information of all the individual underlying manifolds. We
provide an example of a family of similarity graphs, which we call annular proximity graphs
with angle constraints, satisfying these sufficient conditions. We contrast our family of
graphs with other constructions in the literature based on the alignment of tangent planes.
Extensive numerical experiments expand the insights that our theory provides on the MMC
problem.},
  pdf = {http://jmlr.org/papers/v24/21-1254.html}
}

@inproceedings{xu2023probabilistic,
  title={Probabilistic Categorical Adversarial Attack and Adversarial Training},
  author={Xu, Han and He, Pengfei and Ren, Jie and Wan, Yuxuan and Liu, Zitao and Liu, Hui and Tang, Jiliang},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={38428--38442},
  year={2023},
  abstract={The studies on adversarial attacks and defenses
have greatly improved the robustness of Deep
Neural Networks (DNNs). Most advanced approaches have been overwhelmingly designed for
continuous data such as images. However, these
achievements are still hard to be generalized to
categorical data. To bridge this gap, we propose
a novel framework, Probabilistic Categorical Adversarial Attack (or PCAA). It transfers the discrete optimization problem of finding categorical
adversarial examples to a continuous problem that
can be solved via gradient-based methods. We analyze the optimality (attack success rate) and time
complexity of PCAA to demonstrate its significant advantage over current search-based attacks.
More importantly, through extensive empirical
studies, we demonstrate that the well-established
defenses for continuous data, such as adversarial
training and TRADES, can be easily accommodated to defend DNNs for categorical data},
  organization={PMLR},
  pdf = {https://proceedings.mlr.press/v202/xu23e.html}
}
@inproceedings{he2023sharpness,
  title={Sharpness-Aware Data Poisoning Attack},
  author={He, Pengfei and Xu, Han and Ren, Jie and Cui, Yingqian and Liu, Hui and Aggarwal, Charu C and Tang, Jiliang},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024},
  note={Spotlight Paper, 5%},
  abstract={Recent research has highlighted the vulnerability of Deep Neural Networks (DNNs)
against data poisoning attacks. These attacks aim to inject poisoning samples into
the models’ training dataset such that the trained models have inference failures.
While previous studies have executed different types of attacks, one major challenge
that greatly limits their effectiveness is the uncertainty of the re-training process
after the injection of poisoning samples, including the re-training initialization or
algorithms. To address this challenge, we propose a novel attack method called
“Sharpness-Aware Data Poisoning Attack (SAPA)”. In particular, it leverages the
concept of DNNs’ loss landscape sharpness to optimize the poisoning effect on the
worst re-trained model. It helps enhance the preservation of the poisoning effect,
regardless of the specific retraining procedure employed. Extensive experiments
demonstrate that SAPA offers a general and principled strategy that significantly
enhances various types of poisoning attacks.},
  pdf = {/assets/pdf/Sharpness_aware_poisoning_attacks.pdf}
}

@misc{cui2023diffusionshield,
  title={DiffusionShield: A Watermark for Copyright Protection against Generative Diffusion Models},
  author={Cui, Yingqian and Ren, Jie and Xu, Han and He, Pengfei and Liu, Hui and Sun, Lichao and Tang, Jiliang},
  journal={arXiv preprint arXiv:2306.04642},
  year={2023}
}

@article{bjarnadottir2023analyzing,
  title={Analyzing Illegal Psychostimulant Trafficking Networks Using Noisy and Sparse Data},
  author={Bjarnadottir, Margret V and Chandra, Siddharth and He, Pengfei and Midgette, Greg},
  journal={IISE Transactions},
  number={just-accepted},
  pages={1--20},
  year={2023},
  publisher={Taylor \& Francis}
}

@misc{he2023confidencedriven,
      title={Confidence-driven Sampling for Backdoor Attacks}, 
      author={Pengfei He and Han Xu and Yue Xing and Jie Ren and Yingqian Cui and Shenglai Zeng and Jiliang Tang and Makoto Yamada and Mohammad Sabokrou},
      year={2023},
      eprint={2310.05263},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{cui2023ftshield,
      title={FT-Shield: A Watermark Against Unauthorized Fine-tuning in Text-to-Image Diffusion Models}, 
      author={Yingqian Cui and Jie Ren and Yuping Lin and Han Xu and Pengfei He and Yue Xing and Wenqi Fan and Hui Liu and Jiliang Tang},
      year={2023},
      eprint={2310.02401},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{xu2023generalization,
      title={On the Generalization of Training-based ChatGPT Detection Methods}, 
      author={Han Xu and Jie Ren and Pengfei He and Shenglai Zeng and Yingqian Cui and Amy Liu and Hui Liu and Jiliang Tang},
      year={2023},
      eprint={2310.01307},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zeng2023exploring,
      title={Exploring Memorization in Fine-tuned Language Models}, 
      author={Shenglai Zeng and Yaxin Li and Jie Ren and Yiding Liu and Han Xu and Pengfei He and Yue Xing and Shuaiqiang Wang and Jiliang Tang and Dawei Yin},
      year={2023},
      eprint={2310.06714},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}