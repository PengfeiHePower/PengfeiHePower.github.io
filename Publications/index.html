<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Publications | Pengfei  He</title>
    <meta name="author" content="Pengfei  He">
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://pengfeihepower.github.io/Publications/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Pengfei </span>He</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/Publications/">Publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/TA&amp;mentor/">TA&amp;mentor</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">

<!-- <h1>Publications</h1>

<h1>Preprints</h1> -->

<h1>Publications</h1>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">JMLR</abbr></div>

        <!-- Entry bib key -->
        <div id="JMLR:v24:21-1254" class="col-sm-8">
        <!-- Title -->
        <div class="title">Large sample spectral analysis of graph-based multi-manifold clustering</div>
        <!-- Author -->
        <div class="author">
        

        Nicolas Garcia Trillos, <em>Pengfei He</em>, and Chenghui Li</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Journal of Machine Learning Research (JMLR)</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://jmlr.org/papers/v24/21-1254.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this work we study statistical properties of graph-based algorithms for multi-manifold
clustering (MMC). In MMC the goal is to retrieve the multi-manifold structure underlying a
given Euclidean data set when this one is assumed to be obtained by sampling a distribution
on a union of manifolds M = M1 ∪ · · · ∪ MN that may intersect with each other and
that may have different dimensions. We investigate sufficient conditions that similarity
graphs on data sets must satisfy in order for their corresponding graph Laplacians to
capture the right geometric information to solve the MMC problem. Precisely, we provide
high probability error bounds for the spectral approximation of a tensorized Laplacian on
M with a suitable graph Laplacian built from the observations; the recovered tensorized
Laplacian contains all geometric information of all the individual underlying manifolds. We
provide an example of a family of similarity graphs, which we call annular proximity graphs
with angle constraints, satisfying these sufficient conditions. We contrast our family of
graphs with other constructions in the literature based on the alignment of tangent planes.
Extensive numerical experiments expand the insights that our theory provides on the MMC
problem.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SIGKDD Explor. Newsl.</abbr></div>

        <!-- Entry bib key -->
        <div id="10.1145/3715073.3715079" class="col-sm-8">
        <!-- Title -->
        <div class="title">DiffusionShield: A Watermark for Data Copyright Protection against Generative Diffusion Models</div>
        <!-- Author -->
        <div class="author">
        

        Yingqian Cui, Jie Ren, Han Xu, and
          <span class="more-authors" title="click to view 5 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '5 more authors' ? 'Pengfei He, Hui Liu, Lichao Sun, Yue Xing, Jiliang Tang' : '5 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">5 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>SIGKDD Explor. Newsl.</em>, Jan 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3715073.3715079" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1145/3715073.3715079"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1145/3715073.3715079" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recently, Generative Diffusion Models (GDMs) have shown remarkable abilities in learning and generating images, fostering a large community of GDMs. However, the unrestricted proliferation has raised serious concerns on copyright issues. For example, artists become concerned that GDMs could effortlessly replicate their unique artworks without permission. In response to these challenges, we introduce a novel watermark scheme, Diffusion Shield, against GDMs. It protects images from infringement by encoding the ownership message into an imperceptible watermark and injecting it into images. This watermark can be easily learned by GDMs and will be reproduced in generated images. By detecting the watermark in generated images, the infringement can be exposed with evidence. Benefiting from the uniformity of the watermarks and the joint optimization method, Diffusion Shield ensures low distortion of the original image, high watermark detection performance, and lengthy encoded messages. We conduct rigorous and comprehensive experiments to show its effectiveness in defending against infringement by GDMs and its superiority over traditional watermark methods.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">TMLR</abbr></div>

        <!-- Entry bib key -->
        <div id="hestealthy" class="col-sm-8">
        <!-- Title -->
        <div class="title">Stealthy Backdoor Attack via Confidence-driven Sampling</div>
        <!-- Author -->
        <div class="author">
        

        <em>Pengfei He</em>, Yue Xing, Han Xu, and
          <span class="more-authors" title="click to view 6 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '6 more authors' ? 'Jie Ren, Yingqian Cui, Shenglai Zeng, Jiliang Tang, Makoto Yamada, Mohammad Sabokrou' : '6 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">6 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Transactions on Machine Learning Research</em>, Jan 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/pdf?id=Flh5EXz8dA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Backdoor attacks facilitate unauthorized control in the testing stage by carefully injecting
harmful triggers during the training phase of deep neural networks. Previous works have
focused on improving the stealthiness of the trigger while randomly selecting samples to
attack. However, we find that random selection harms the stealthiness of the model. In
this paper, we identify significant pitfalls of random sampling, which make the attacks more
detectable and easier to defend against. To improve the stealthiness of existing attacks, we
introduce a method of strategically poisoning samples near the model’s decision boundary,
aiming to minimally alter the model’s behavior (decision boundary) before and after backdooring. Our main insight for detecting boundary samples is exploiting the confidence scores
as a metric for being near the decision boundary and selecting those to poison (inject) the
attack. The proposed approach makes it significantly harder for defenders to identify the
attacks. Our method is versatile and independent of any specific trigger design. We provide
theoretical insights and conduct extensive experiments to demonstrate the effectiveness of
the proposed method.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SIGKDD Explor. Newsl.</abbr></div>

        <!-- Entry bib key -->
        <div id="10.1145/3715073.3715080" class="col-sm-8">
        <!-- Title -->
        <div class="title">FT-Shield: A Watermark Against Unauthorized Fine-tuning in Text-to-Image Diffusion Models</div>
        <!-- Author -->
        <div class="author">
        

        Yingqian Cui, Jie Ren, Yuping Lin, and
          <span class="more-authors" title="click to view 7 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '7 more authors' ? 'Han Xu, Pengfei He, Yue Xing, Lingjuan Lyu, Wenqi Fan, Hui Liu, Jiliang Tang' : '7 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">7 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>SIGKDD Explor. Newsl.</em>, Jan 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3715073.3715080" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1145/3715073.3715080"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1145/3715073.3715080" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Text-to-image generative models, especially those based on latent diffusion models (LDMs), have demonstrated outstanding ability in generating high-quality and high-resolution images from textual prompts. With this advancement, various fine-tuning methods have been developed to personalize text-to-image models for specific applications such as artistic style adaptation and human face transfer. However, such advancements have raised copyright concerns, especially when the data are used for personalization without authorization. For example, a malicious user can employ fine-tuning techniques to replicate the style of an artist without consent. In light of this concern, we propose FT-Shield, a watermarking solution tailored for the fine-tuning of text-to-image diffusion models. FT-Shield addresses copyright protection challenges by designing new watermark generation and detection strategies. In particular, it introduces an innovative algorithm for watermark generation. It ensures the seamless transfer of watermarks from training images to generated outputs, facilitating the identification of copyrighted material use. To tackle the variability in fine-tuning methods and their impact on watermark detection, FT-Shield integrates a Mixture of Experts (MoE) approach for watermark detection. Comprehensive experiments validate the effectiveness of our proposed FT-Shield.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeruIPS workshop</abbr></div>

        <!-- Entry bib key -->
        <div id="he2024towards" class="col-sm-8">
        <!-- Title -->
        <div class="title">Towards the Effect of Examples on In-Context Learning: A Theoretical Case Study</div>
        <!-- Author -->
        <div class="author">
        

        <em>Pengfei He</em>, Yingqian Cui, Han Xu, and
          <span class="more-authors" title="click to view 4 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '4 more authors' ? 'Hui Liu, Makoto Yamada, Jiliang Tang, Yue Xing' : '4 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">4 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>M3L &amp; SFLLM workshop NeruIPS 2024</em>, Jan 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Stat</abbr></div>

        <!-- Entry bib key -->
        <div id="he2024towardt" class="col-sm-8">
        <!-- Title -->
        <div class="title">Towards the Effect of Examples on In-Context Learning: A Theoretical Case Study</div>
        <!-- Author -->
        <div class="author">
        

        <em>Pengfei He</em>, Yingqian Cui, Han Xu, and
          <span class="more-authors" title="click to view 4 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '4 more authors' ? 'Hui Liu, Makoto Yamada, Jiliang Tang, Yue Xing' : '4 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">4 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Stat</em>, Jan 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
</ol>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CIKM</abbr></div>

        <!-- Entry bib key -->
        <div id="10.1145/3511808.3557130" class="col-sm-8">
        <!-- Title -->
        <div class="title">PROPN: Personalized Probabilistic Strategic Parameter Optimization in Recommendations</div>
        <!-- Author -->
        <div class="author">
        

        <em>Pengfei He</em>, Haochen Liu, Xiangyu Zhao, and
          <span class="more-authors" title="click to view 2 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '2 more authors' ? 'Hui Liu, Jiliang Tang' : '2 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">2 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management (CIKM)</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1145/3511808.3557130"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1145/3511808.3557130" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="xu2023probabilistic" class="col-sm-8">
        <!-- Title -->
        <div class="title">Probabilistic Categorical Adversarial Attack and Adversarial Training</div>
        <!-- Author -->
        <div class="author">
        

        Han Xu, <em>Pengfei He</em>, Jie Ren, and
          <span class="more-authors" title="click to view 4 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '4 more authors' ? 'Yuxuan Wan, Zitao Liu, Hui Liu, Jiliang Tang' : '4 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">4 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Machine Learning (ICML)</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.mlr.press/v202/xu23e.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The studies on adversarial attacks and defenses
have greatly improved the robustness of Deep
Neural Networks (DNNs). Most advanced approaches have been overwhelmingly designed for
continuous data such as images. However, these
achievements are still hard to be generalized to
categorical data. To bridge this gap, we propose
a novel framework, Probabilistic Categorical Adversarial Attack (or PCAA). It transfers the discrete optimization problem of finding categorical
adversarial examples to a continuous problem that
can be solved via gradient-based methods. We analyze the optimality (attack success rate) and time
complexity of PCAA to demonstrate its significant advantage over current search-based attacks.
More importantly, through extensive empirical
studies, we demonstrate that the well-established
defenses for continuous data, such as adversarial
training and TRADES, can be easily accommodated to defend DNNs for categorical data</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR Spotlight</abbr></div>

        <!-- Entry bib key -->
        <div id="he2023sharpness" class="col-sm-8">
        <!-- Title -->
        <div class="title">Sharpness-Aware Data Poisoning Attack</div>
        <!-- Author -->
        <div class="author">
        

        <em>Pengfei He</em>, Han Xu, Jie Ren, and
          <span class="more-authors" title="click to view 4 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '4 more authors' ? 'Yingqian Cui, Hui Liu, Charu C Aggarwal, Jiliang Tang' : '4 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">4 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Learning Representations (ICLR)</em>, 2024
        </div>
        <div class="periodical">
          Spotlight Paper, 5%
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="/assets/pdf//assets/pdf/Sharpness_aware_poisoning_attacks.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recent research has highlighted the vulnerability of Deep Neural Networks (DNNs)
against data poisoning attacks. These attacks aim to inject poisoning samples into
the models’ training dataset such that the trained models have inference failures.
While previous studies have executed different types of attacks, one major challenge
that greatly limits their effectiveness is the uncertainty of the re-training process
after the injection of poisoning samples, including the re-training initialization or
algorithms. To address this challenge, we propose a novel attack method called
“Sharpness-Aware Data Poisoning Attack (SAPA)”. In particular, it leverages the
concept of DNNs’ loss landscape sharpness to optimize the poisoning effect on the
worst re-trained model. It helps enhance the preservation of the poisoning effect,
regardless of the specific retraining procedure employed. Extensive experiments
demonstrate that SAPA offers a general and principled strategy that significantly
enhances various types of poisoning attacks.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div>

        <!-- Entry bib key -->
        <div id="zeng-etal-2024-good" class="col-sm-8">
        <!-- Title -->
        <div class="title">The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)</div>
        <!-- Author -->
        <div class="author">
        

        Shenglai Zeng, Jiankun Zhang, <em>Pengfei He</em>, and
          <span class="more-authors" title="click to view 8 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '8 more authors' ? 'Yiding Liu, Yue Xing, Han Xu, Jie Ren, Yi Chang, Shuaiqiang Wang, Dawei Yin, Jiliang Tang' : '8 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">8 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Findings of the Association for Computational Linguistics ACL 2024</em>, Aug 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://aclanthology.org/2024.findings-acl.267/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.18653/v1/2024.findings-acl.267"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2024.findings-acl.267" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Retrieval-augmented generation (RAG) is a powerful technique to facilitate language model generation with proprietary and private data, where data privacy is a pivotal concern. Whereas extensive research has demonstrated the privacy risks of large language models (LLMs), the RAG technique could potentially reshape the inherent behaviors of LLM generation, posing new privacy issues that are currently under-explored. To this end, we conduct extensive empirical studies with novel attack methods, which demonstrate the vulnerability of RAG systems on leaking the private retrieval database. Despite the new risks brought by RAG on the retrieval data, we further discover that RAG can be used to mitigate the old risks, i.e., the leakage of the LLMs’ training data. In general, we reveal many new insights in this paper for privacy protection of retrieval-augmented LLMs, which could benefit both LLMs and RAG systems builders.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div>

        <!-- Entry bib key -->
        <div id="zeng-etal-2024-exploring" class="col-sm-8">
        <!-- Title -->
        <div class="title">Exploring Memorization in Fine-tuned Language Models</div>
        <!-- Author -->
        <div class="author">
        

        Shenglai Zeng, Yaxin Li, Jie Ren, and
          <span class="more-authors" title="click to view 7 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '7 more authors' ? 'Yiding Liu, Han Xu, Pengfei He, Yue Xing, Shuaiqiang Wang, Jiliang Tang, Dawei Yin' : '7 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">7 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Aug 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.18653/v1/2024.acl-long.216"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2024.acl-long.216" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Large language models (LLMs) have shown great capabilities in various tasks but also exhibited memorization of training data, raising tremendous privacy and copyright concerns. While prior works have studied memorization during pre-training, the exploration of memorization during fine-tuning is rather limited. Compared to pre-training, fine-tuning typically involves more sensitive data and diverse objectives, thus may bring distinct privacy risks and unique memorization behaviors. In this work, we conduct the first comprehensive analysis to explore language models’ (LMs) memorization during fine-tuning across tasks. Our studies with open-sourced and our own fine-tuned LMs across various tasks indicate that memorization presents a strong disparity among different fine-tuning tasks. We provide an intuitive explanation of this task disparity via sparse coding theory and unveil a strong correlation between memorization and attention score distribution.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div>

        <!-- Entry bib key -->
        <div id="xu2023generalization" class="col-sm-8">
        <!-- Title -->
        <div class="title">On the Generalization of Training-based ChatGPT Detection Methods</div>
        <!-- Author -->
        <div class="author">
        

        Han Xu, Jie Ren, <em>Pengfei He</em>, and
          <span class="more-authors" title="click to view 5 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '5 more authors' ? 'Shenglai Zeng, Yingqian Cui, Amy Liu, Hui Liu, Jiliang Tang' : '5 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">5 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>, Dec 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>ChatGPT is one of the most popular language models which achieve amazing performance on various natural language tasks. Consequently, there is also an urgent need to detect the texts generated ChatGPT from human written. One of the extensively studied methods trains classification models to distinguish both. However, existing studies also demonstrate that the trained models may suffer from distribution shifts (during test), i.e., they are ineffective to predict the generated texts from unseen language tasks or topics. In this work, we aim to have a comprehensive investigation on these methods’ generalization behaviors under distribution shift caused by a wide range of factors, including prompts, text lengths, topics, and language tasks. To achieve this goal, we first collect a new dataset with human and ChatGPT texts, and then we conduct extensive studies on the collected dataset. Our studies unveil insightful findings which provide guidance for developing future methodologies or data collection strategies for ChatGPT detection.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div>

        <!-- Entry bib key -->
        <div id="lin2024towards" class="col-sm-8">
        <!-- Title -->
        <div class="title">Towards Understanding Jailbreak Attacks in LLMs: A Representation Space Analysis</div>
        <!-- Author -->
        <div class="author">
        

        <em>Pengfei He</em>, Yuping Lin, Han Xu, and
          <span class="more-authors" title="click to view 4 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '4 more authors' ? 'Yue Xing, Makoto Yamada, Hui Liu, Jiliang Tang' : '4 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">4 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>, Dec 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Large language models (LLMs) are susceptible to a type of attack known as jailbreaking, which misleads LLMs to output harmful contents. Although there are diverse jailbreak attack strategies, there is no unified understanding on why some methods succeed and others fail. This paper explores the behavior of harmful and harmless prompts in the LLM’s representation space to investigate the intrinsic properties of successful jailbreak attacks. We hypothesize that successful attacks share some similar properties: They are effective in moving the representation of the harmful prompt towards the direction to the harmless prompts. We leverage hidden representations into the objective of existing jailbreak attacks to move the attacks along the acceptance direction, and conduct experiments to validate the above hypothesis using the proposed objective. We hope this study provides new insights into understanding how LLMs understand harmfulness information.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NAACL</abbr></div>

        <!-- Entry bib key -->
        <div id="he2024data" class="col-sm-8">
        <!-- Title -->
        <div class="title">Data Poisoning for In-context Learning</div>
        <!-- Author -->
        <div class="author">
        

        <em>Pengfei He</em>, Han Xu, Yue Xing, and
          <span class="more-authors" title="click to view 3 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '3 more authors' ? 'Hui Liu, Makoto Yamada, Jiliang Tang' : '3 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">3 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 2025 Conference of the North American Chapter of the Association for Computational Linguistics</em>, Apr 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In the domain of large language models (LLMs), in-context 
      learning (ICL) has been recognized for its innovative ability to adapt to new tasks, 
      relying on examples rather than retraining or fine-tuning. This paper delves into 
      the critical issue of ICL’s susceptibility to data poisoning attacks, an area not 
      yet fully explored. We wonder whether ICL is vulnerable, with adversaries capable 
      of manipulating example data to degrade model performance. To address this, 
      we introduce ICLPoison, a specialized attacking framework conceived to exploit 
      the learning mechanisms of ICL. Our approach uniquely employs discrete text 
      perturbations to strategically influence the hidden states of LLMs during the 
      ICL process. We outline three representative strategies to implement attacks 
      under our framework, each rigorously evaluated across a variety of models and 
      tasks. Our comprehensive tests, including trials on the sophisticated GPT-4 model, 
      demonstrate that ICL’s performance is significantly compromised under our framework. 
      These revelations indicate an urgent need for enhanced defense mechanisms to safeguard 
      the integrity and reliability of LLMs in applications relying on in-context learning.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AISTATS</abbr></div>

        <!-- Entry bib key -->
        <div id="cui2024superiority" class="col-sm-8">
        <!-- Title -->
        <div class="title">Superiority of Multi-Head Attention in In-Context Linear Regression</div>
        <!-- Author -->
        <div class="author">
        

        Yingqian Cui, Jie Ren, <em>Pengfei He</em>, and
          <span class="more-authors" title="click to view 2 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '2 more authors' ? 'Jiliang Tang, Yue Xing' : '2 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">2 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In </em>, Apr 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present a theoretical analysis of the performance of transformer with softmax attention in in-context learning with linear regression tasks. While the existing literature predominantly focuses on the convergence of transformers with single-/multi-head attention, our research centers on comparing their performance. We conduct an exact theoretical analysis to demonstrate that multi-head attention with a substantial embedding dimension performs better than single-head attention. When the number of in-context examples D increases, the prediction loss using single-/multi-head attention is in O(1/D), and the one for multi-head attention has a smaller multiplicative constant. In addition to the simplest data distribution setting, we consider more scenarios, e.g., noisy labels, local examples, correlated features, and prior knowledge. We observe that, in general, multi-head attention is preferred over single-head attention. Our results verify the effectiveness of the design of multi-head attention in the transformer architecture.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AISTSTS</abbr></div>

        <!-- Entry bib key -->
        <div id="Cui2024ATU" class="col-sm-8">
        <!-- Title -->
        <div class="title">A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration</div>
        <!-- Author -->
        <div class="author">
        

        Yingqian Cui, <em>Pengfei He</em>, Xianfeng Tang, and
          <span class="more-authors" title="click to view 4 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '4 more authors' ? 'Qi He, Chen Luo, Jiliang Tang, Yue Xing' : '4 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">4 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In </em>, Apr 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Few-shot Chain-of-Thought (CoT) prompting has demonstrated strong performance in improving the reasoning capabilities of large language models (LLMs). While theoretical investigations have been conducted to understand CoT, the underlying transformer used in these studies isolates the CoT reasoning process into separated in-context learning steps (Stepwise ICL). In this work, we theoretically show that, compared to Stepwise ICL, the transformer gains better error correction ability and more accurate predictions if the reasoning from earlier steps (Coherent CoT) is integrated. Given that this coherent reasoning changes the behavior of the transformer, we further investigate the sensitivity of the transformer with Coherent CoT when the demonstration examples are corrupted at the inference stage. Our theoretical results indicate that the transformer is more sensitive to errors in intermediate reasoning steps than the final outcome. Building upon this observation, we propose an improvement on CoT by incorporating both correct and incorrect reasoning paths in the demonstration. Our experiments validate the effectiveness of the proposed approach.</p>
          </div>
        </div>
      </div>
</li>
</ol>

<h1>Preprints</h1>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">preprint</abbr></div>

        <!-- Entry bib key -->
        <div id="ren2024copyright" class="col-sm-8">
        <!-- Title -->
        <div class="title">Copyright Protection in Generative AI: A Technical Perspective</div>
        <!-- Author -->
        <div class="author">
        

        Jie Ren, Han Xu, <em>Pengfei He</em>, and
          <span class="more-authors" title="click to view 8 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '8 more authors' ? 'Yingqian Cui, Shenglai Zeng, Jiankun Zhang, Hongzhi Wen, Jiayuan Ding, Hui Liu, Yi Chang, Jiliang Tang' : '8 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">8 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2402.02333"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">preprint</abbr></div>

        <!-- Entry bib key -->
        <div id="he2024makellmsbetterzeroshot" class="col-sm-8">
        <!-- Title -->
        <div class="title">Make LLMs better zero-shot reasoners: Structure-orientated autonomous reasoning</div>
        <!-- Author -->
        <div class="author">
        

        <em>Pengfei He</em>, Zitao Li, Yue Xing, and
          <span class="more-authors" title="click to view 3 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '3 more authors' ? 'Yaling Li, Jiliang Tang, Bolin Ding' : '3 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">3 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2410.19000"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
</ol>

</div>

          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Pengfei  He. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', '');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
